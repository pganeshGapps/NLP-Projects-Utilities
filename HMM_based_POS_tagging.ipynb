{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi Algorithm:\n",
    "\n",
    "In this project we apply techniques to improve Vanilla Viterbi Algorithm. Following are the steps followed:\n",
    "\n",
    "1. plain vanilla Viterbi Algorithm is developed.\n",
    "2. Viterbi Modification-Technique I - approach:\n",
    "    * Transition probability is considered in case of unknown words.\n",
    "    * The above approach is modified to consider transition probability weighted by tag occurrence probability in training set.\n",
    "3. Viterbi Modification-Technique II - approach:\n",
    "     * backoff to a rule based tagger in case of an unknown word.\n",
    "     * The above technique is modified by using transition probability in approach 2 above if rule based tagger returns default noun tag ('NN').\n",
    "4. The modified Viterbi algorithms are first tested on sampled test data for comparison.\n",
    "5. The final algorithm and vanilla Viterbi Algorithm are the tested on full testing data for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pprint, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Mr.', 'NOUN'), ('Vinken', 'NOUN'), ('is', 'VERB'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Elsevier', 'NOUN'), ('N.V.', 'NOUN'), (',', '.'), ('the', 'DET'), ('Dutch', 'NOUN'), ('publishing', 'VERB'), ('group', 'NOUN'), ('.', '.')], [('Rudolph', 'NOUN'), ('Agnew', 'NOUN'), (',', '.'), ('55', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), ('and', 'CONJ'), ('former', 'ADJ'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Consolidated', 'NOUN'), ('Gold', 'NOUN'), ('Fields', 'NOUN'), ('PLC', 'NOUN'), (',', '.'), ('was', 'VERB'), ('named', 'VERB'), ('*-1', 'X'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('of', 'ADP'), ('this', 'DET'), ('British', 'ADJ'), ('industrial', 'ADJ'), ('conglomerate', 'NOUN'), ('.', '.')], [('A', 'DET'), ('form', 'NOUN'), ('of', 'ADP'), ('asbestos', 'NOUN'), ('once', 'ADV'), ('used', 'VERB'), ('*', 'X'), ('*', 'X'), ('to', 'PRT'), ('make', 'VERB'), ('Kent', 'NOUN'), ('cigarette', 'NOUN'), ('filters', 'NOUN'), ('has', 'VERB'), ('caused', 'VERB'), ('a', 'DET'), ('high', 'ADJ'), ('percentage', 'NOUN'), ('of', 'ADP'), ('cancer', 'NOUN'), ('deaths', 'NOUN'), ('among', 'ADP'), ('a', 'DET'), ('group', 'NOUN'), ('of', 'ADP'), ('workers', 'NOUN'), ('exposed', 'VERB'), ('*', 'X'), ('to', 'PRT'), ('it', 'PRON'), ('more', 'ADV'), ('than', 'ADP'), ('30', 'NUM'), ('years', 'NOUN'), ('ago', 'ADP'), (',', '.'), ('researchers', 'NOUN'), ('reported', 'VERB'), ('0', 'X'), ('*T*-1', 'X'), ('.', '.')], [('The', 'DET'), ('asbestos', 'NOUN'), ('fiber', 'NOUN'), (',', '.'), ('crocidolite', 'NOUN'), (',', '.'), ('is', 'VERB'), ('unusually', 'ADV'), ('resilient', 'ADJ'), ('once', 'ADP'), ('it', 'PRON'), ('enters', 'VERB'), ('the', 'DET'), ('lungs', 'NOUN'), (',', '.'), ('with', 'ADP'), ('even', 'ADV'), ('brief', 'ADJ'), ('exposures', 'NOUN'), ('to', 'PRT'), ('it', 'PRON'), ('causing', 'VERB'), ('symptoms', 'NOUN'), ('that', 'DET'), ('*T*-1', 'X'), ('show', 'VERB'), ('up', 'PRT'), ('decades', 'NOUN'), ('later', 'ADJ'), (',', '.'), ('researchers', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('*T*-2', 'X'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "# let's check some of the tagged data\n",
    "print(nltk_data[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and validation set in the ratio 95:5\n",
    "\n",
    "train_set,test_set = train_test_split(nltk_data,train_size=0.95,test_size=0.05,random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95547\n",
      "5129\n"
     ]
    }
   ],
   "source": [
    "# create list of train and test tagged words\n",
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "test_tagged_words = [tup[0] for sent in test_set for tup in sent]\n",
    "print(len(train_tagged_words))\n",
    "print(len(test_tagged_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('confirmed', 'VERB'), ('the', 'DET'), ('filing', 'NOUN'), ('but', 'CONJ')]"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check some of the tagged words.\n",
    "train_tagged_words[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "{'NUM', 'ADP', 'ADV', '.', 'NOUN', 'ADJ', 'PRT', 'PRON', 'DET', 'VERB', 'CONJ', 'X'}\n"
     ]
    }
   ],
   "source": [
    "# let's check how many unique tags are present in training data\n",
    "tags = {tag for word,tag in train_tagged_words}\n",
    "print(len(tags))\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12100\n"
     ]
    }
   ],
   "source": [
    "# let's check how many words are present in vocabulary\n",
    "vocab = {word for word,tag in train_tagged_words}\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging algorithm using Hidden Markov Model (HMM)\n",
    "\n",
    "We'll use the HMM algorithm to tag the words. Given a sequence of words to be tagged, the task is to assign the most probable tag to the word. \n",
    "In other words, to every **word w**, assign **the tag t** that maximises the likelihood **P(t/w)**. \n",
    "\n",
    "Since P(t/w) = P(w/t). P(t) / P(w), after ignoring P(w), we have to compute P(w/t) and P(t).\n",
    "\n",
    "Now:\n",
    "* **P(w/t): is the emission probability** of a given word for a given tag. This can be computed based on the fraction of given word for given tag to the total count of that tag, ie: P(w/t) = count(w, t) / count(t). \n",
    "\n",
    "* **P(t): is the probability of tag (also transition probability)**, and in a tagging task, we assume that a tag will depend only on the previous tag (Markov order 1 assumption). In other words, the probability of say a tag being NN will depend only on the previous tag t(n-1). So for e.g. if t(n-1) is a JJ, then t(n) is likely to be an NN since adjectives often precede a noun (blue coat, tall building etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to compute emission probabilties for a given word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute emission probability for a given word for a given tag\n",
    "def word_given_tag(word,tag,train_bag= train_tagged_words):\n",
    "    taglist = [pair for pair in train_bag if pair[1] == tag]\n",
    "    tag_count = len(taglist)    \n",
    "    w_in_tag = [pair[0] for pair in taglist if pair[0]==word]    \n",
    "    word_count_given_tag = len(w_in_tag)    \n",
    "    \n",
    "    return (word_count_given_tag,tag_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to compute transition probabilties for a given tag and previous tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute transition probabilities of a previous and next tag\n",
    "def t2_given_t1(t2,t1,train_bag=train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    \n",
    "    t1_tags = [tag for tag in tags if tag==t1]\n",
    "    \n",
    "    count_of_t1 = len(t1_tags)\n",
    "    \n",
    "    t2_given_t1 = [tags[index+1] for index in range(len(tags)-1) if tags[index] == t1 and tags[index+1] == t2]\n",
    "    \n",
    "    count_t2_given_t1 = len(t2_given_t1)\n",
    "    \n",
    "    return(count_t2_given_t1,count_of_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5284, 8281)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2_given_t1('NOUN','DET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating t x t transition matrix of tags\n",
    "# each column is t2, each row is t1\n",
    "# thus M(i, j) represents P(tj given ti)\n",
    "\n",
    "tags_matrix = np.zeros((len(tags), len(tags)), dtype='float32')\n",
    "for i, t1 in enumerate(list(tags)):\n",
    "    for j, t2 in enumerate(list(tags)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the matrix to a df for better readability\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(tags), index=list(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUM</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>.</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>PRT</th>\n",
       "      <th>PRON</th>\n",
       "      <th>DET</th>\n",
       "      <th>VERB</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.184932</td>\n",
       "      <td>0.036033</td>\n",
       "      <td>0.002978</td>\n",
       "      <td>0.117332</td>\n",
       "      <td>0.350208</td>\n",
       "      <td>0.034247</td>\n",
       "      <td>0.026504</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>0.003276</td>\n",
       "      <td>0.018761</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.210542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.062226</td>\n",
       "      <td>0.016893</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.039025</td>\n",
       "      <td>0.320967</td>\n",
       "      <td>0.107024</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.070031</td>\n",
       "      <td>0.324709</td>\n",
       "      <td>0.008340</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.034427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.030474</td>\n",
       "      <td>0.118582</td>\n",
       "      <td>0.080490</td>\n",
       "      <td>0.137131</td>\n",
       "      <td>0.031467</td>\n",
       "      <td>0.129182</td>\n",
       "      <td>0.014243</td>\n",
       "      <td>0.014906</td>\n",
       "      <td>0.069891</td>\n",
       "      <td>0.343491</td>\n",
       "      <td>0.006956</td>\n",
       "      <td>0.023186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.081003</td>\n",
       "      <td>0.091342</td>\n",
       "      <td>0.052324</td>\n",
       "      <td>0.093320</td>\n",
       "      <td>0.222242</td>\n",
       "      <td>0.043963</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.066349</td>\n",
       "      <td>0.173335</td>\n",
       "      <td>0.089095</td>\n",
       "      <td>0.057538</td>\n",
       "      <td>0.026971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.009542</td>\n",
       "      <td>0.176514</td>\n",
       "      <td>0.017074</td>\n",
       "      <td>0.240604</td>\n",
       "      <td>0.263564</td>\n",
       "      <td>0.012248</td>\n",
       "      <td>0.043397</td>\n",
       "      <td>0.004607</td>\n",
       "      <td>0.012942</td>\n",
       "      <td>0.147667</td>\n",
       "      <td>0.042666</td>\n",
       "      <td>0.029175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.021256</td>\n",
       "      <td>0.078267</td>\n",
       "      <td>0.004778</td>\n",
       "      <td>0.063931</td>\n",
       "      <td>0.699621</td>\n",
       "      <td>0.066403</td>\n",
       "      <td>0.010710</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.004943</td>\n",
       "      <td>0.011699</td>\n",
       "      <td>0.016971</td>\n",
       "      <td>0.021091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0.056672</td>\n",
       "      <td>0.020099</td>\n",
       "      <td>0.010214</td>\n",
       "      <td>0.043822</td>\n",
       "      <td>0.247776</td>\n",
       "      <td>0.083031</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>0.017792</td>\n",
       "      <td>0.097858</td>\n",
       "      <td>0.405272</td>\n",
       "      <td>0.002306</td>\n",
       "      <td>0.013509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.006508</td>\n",
       "      <td>0.022971</td>\n",
       "      <td>0.034074</td>\n",
       "      <td>0.040965</td>\n",
       "      <td>0.210949</td>\n",
       "      <td>0.073124</td>\n",
       "      <td>0.013017</td>\n",
       "      <td>0.007657</td>\n",
       "      <td>0.009954</td>\n",
       "      <td>0.485452</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>0.089969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.022220</td>\n",
       "      <td>0.009540</td>\n",
       "      <td>0.012438</td>\n",
       "      <td>0.017993</td>\n",
       "      <td>0.638087</td>\n",
       "      <td>0.204323</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.003744</td>\n",
       "      <td>0.005676</td>\n",
       "      <td>0.039850</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.045405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.022851</td>\n",
       "      <td>0.092022</td>\n",
       "      <td>0.081952</td>\n",
       "      <td>0.034934</td>\n",
       "      <td>0.110070</td>\n",
       "      <td>0.064988</td>\n",
       "      <td>0.030674</td>\n",
       "      <td>0.035786</td>\n",
       "      <td>0.134392</td>\n",
       "      <td>0.169249</td>\n",
       "      <td>0.005577</td>\n",
       "      <td>0.217506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0.039981</td>\n",
       "      <td>0.052534</td>\n",
       "      <td>0.055323</td>\n",
       "      <td>0.034868</td>\n",
       "      <td>0.349140</td>\n",
       "      <td>0.118085</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>0.058113</td>\n",
       "      <td>0.121339</td>\n",
       "      <td>0.156671</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.008833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.002864</td>\n",
       "      <td>0.142584</td>\n",
       "      <td>0.024984</td>\n",
       "      <td>0.163590</td>\n",
       "      <td>0.062381</td>\n",
       "      <td>0.017187</td>\n",
       "      <td>0.185232</td>\n",
       "      <td>0.055538</td>\n",
       "      <td>0.054742</td>\n",
       "      <td>0.203851</td>\n",
       "      <td>0.010662</td>\n",
       "      <td>0.076384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           NUM       ADP       ADV         .      NOUN       ADJ       PRT  \\\n",
       "NUM   0.184932  0.036033  0.002978  0.117332  0.350208  0.034247  0.026504   \n",
       "ADP   0.062226  0.016893  0.014006  0.039025  0.320967  0.107024  0.001390   \n",
       "ADV   0.030474  0.118582  0.080490  0.137131  0.031467  0.129182  0.014243   \n",
       ".     0.081003  0.091342  0.052324  0.093320  0.222242  0.043963  0.002427   \n",
       "NOUN  0.009542  0.176514  0.017074  0.240604  0.263564  0.012248  0.043397   \n",
       "ADJ   0.021256  0.078267  0.004778  0.063931  0.699621  0.066403  0.010710   \n",
       "PRT   0.056672  0.020099  0.010214  0.043822  0.247776  0.083031  0.001647   \n",
       "PRON  0.006508  0.022971  0.034074  0.040965  0.210949  0.073124  0.013017   \n",
       "DET   0.022220  0.009540  0.012438  0.017993  0.638087  0.204323  0.000242   \n",
       "VERB  0.022851  0.092022  0.081952  0.034934  0.110070  0.064988  0.030674   \n",
       "CONJ  0.039981  0.052534  0.055323  0.034868  0.349140  0.118085  0.004649   \n",
       "X     0.002864  0.142584  0.024984  0.163590  0.062381  0.017187  0.185232   \n",
       "\n",
       "          PRON       DET      VERB      CONJ         X  \n",
       "NUM   0.001489  0.003276  0.018761  0.013699  0.210542  \n",
       "ADP   0.070031  0.324709  0.008340  0.000962  0.034427  \n",
       "ADV   0.014906  0.069891  0.343491  0.006956  0.023186  \n",
       ".     0.066349  0.173335  0.089095  0.057538  0.026971  \n",
       "NOUN  0.004607  0.012942  0.147667  0.042666  0.029175  \n",
       "ADJ   0.000330  0.004943  0.011699  0.016971  0.021091  \n",
       "PRT   0.017792  0.097858  0.405272  0.002306  0.013509  \n",
       "PRON  0.007657  0.009954  0.485452  0.005360  0.089969  \n",
       "DET   0.003744  0.005676  0.039850  0.000483  0.045405  \n",
       "VERB  0.035786  0.134392  0.169249  0.005577  0.217506  \n",
       "CONJ  0.058113  0.121339  0.156671  0.000465  0.008833  \n",
       "X     0.055538  0.054742  0.203851  0.010662  0.076384  "
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viterbi Algorithm\n",
    "\n",
    "The steps are as follows:\n",
    "\n",
    "1. Given a sequence of words\n",
    "2. iterate through the sequence\n",
    "3. for each word (starting from first word in sequence) calculate the product of emission probabilties and transition probabilties for all possible tags.\n",
    "4. assign the tag which has maximum probability obtained in step 3 above.\n",
    "5. move to the next word in sequence to repeat steps 3 and 4 above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla Viterbi Algorithm\n",
    "def Viterbi(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    \n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Vanilla Viterbi Algorithm on sampled test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test our Viterbi algorithm on a few sample sentences of test dataset\n",
    "\n",
    "random.seed(1234)\n",
    "\n",
    "# choose random 5 sents\n",
    "rndom = [random.randint(1,len(test_set)) for x in range(5)]\n",
    "\n",
    "# list of sents\n",
    "test_run = [test_set[i] for i in rndom]\n",
    "\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  39.22344136238098\n",
      "Vanilla Viterbi Algorithm Accuracy:  89.38053097345133\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "\n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Vanilla Viterbi Algorithm Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Contra', 'NUM'), ('Contra', 'NOUN')),\n",
       " (('command', 'VERB'), ('command', 'NOUN')),\n",
       " (('Honduras', 'NUM'), ('Honduras', 'NOUN')),\n",
       " (('Sandinista', 'NUM'), ('Sandinista', 'NOUN')),\n",
       " (('offensive', 'NUM'), ('offensive', 'NOUN')),\n",
       " (('rebel', 'NUM'), ('rebel', 'NOUN')),\n",
       " (('Bucking', 'NUM'), ('Bucking', 'VERB')),\n",
       " (('drew', 'NUM'), ('drew', 'VERB')),\n",
       " (('Eveready', 'NUM'), ('Eveready', 'NOUN')),\n",
       " (('*T*-252', 'NUM'), ('*T*-252', 'X')),\n",
       " (('complaining', 'NUM'), ('complaining', 'VERB')),\n",
       " (('up', 'ADV'), ('up', 'PRT'))]"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the incorrectly tagged words\n",
    "[j for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0] != j[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the problem of unknown words\n",
    "We can see that all of unknown words have been tagged as 'NUM' as 'NUM' is the first tag in tag list and is assigned\n",
    "if unknown word is encountered (emission probability =0).\n",
    "\n",
    "### Viterbi Modification-Technique I\n",
    "\n",
    "* **First solution for unknown words**: assign based on transition probabilities only in case of unknown words as emission probability for unknown word is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use transition probability of tags when emission probability is zero (in case of unknown words)\n",
    "\n",
    "def Viterbi_1(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        p_transition =[] # list for storing transition probabilities\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            p_transition.append(transition_p)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        state_max = T[p.index(pmax)] \n",
    "        \n",
    "      \n",
    "        # if probability is zero (unknown word) then use transition probability\n",
    "        if(pmax==0):\n",
    "            pmax = max(p_transition)\n",
    "            state_max = T[p_transition.index(pmax)]\n",
    "                           \n",
    "        else:\n",
    "            state_max = T[p.index(pmax)] \n",
    "        \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  37.800609827041626\n",
      "Modified Viterbi_1 Accuracy:  94.69026548672566\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_1(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Modified Viterbi_1 Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding Tag occurance probability weights**: \n",
    "we will apply weights based on the probability of tag occurance to the transition probabilities of tags and then use the resulting probability for predicting unknown words. \n",
    "\n",
    "This scheme will also take into account that some POS tags are more likely to occur as compared to others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NUM', 0.035145007169246546),\n",
       " ('ADP', 0.0978889970381069),\n",
       " ('ADV', 0.031597015081582885),\n",
       " ('.', 0.11641391147812072),\n",
       " ('NOUN', 0.2862674913916711),\n",
       " ('ADJ', 0.06351847781719991),\n",
       " ('PRT', 0.03176447193527793),\n",
       " ('PRON', 0.0273373313657153),\n",
       " ('DET', 0.08666938784053921),\n",
       " ('VERB', 0.1351167488251855),\n",
       " ('CONJ', 0.02251248076862696),\n",
       " ('X', 0.06576867928872701)]"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets create a list containing tuples of POS tags and POS tag occurance probability, based on training data\n",
    "tag_prob = []\n",
    "total_tag = len([tag for word,tag in train_tagged_words])\n",
    "for t in tags:\n",
    "    each_tag = [tag for word,tag in train_tagged_words if tag==t]\n",
    "    tag_prob.append((t,len(each_tag)/total_tag))\n",
    "\n",
    "tag_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_1(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        p_transition =[] # list for storing transition probabilities\n",
    "       \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "            # find POS tag occurance probability\n",
    "            tag_p = [pair[1] for pair in tag_prob if pair[0]==tag ]\n",
    "            \n",
    "            # calculate the transition prob weighted by tag occurance probability.\n",
    "            transition_p = tag_p[0]*transition_p             \n",
    "            p_transition.append(transition_p)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        state_max = T[p.index(pmax)] \n",
    "        \n",
    "      \n",
    "        # if probability is zero (unknown word) then use weighted transition probability\n",
    "        if(pmax==0):\n",
    "            pmax = max(p_transition)\n",
    "            state_max = T[p_transition.index(pmax)]                 \n",
    "                           \n",
    "        else:\n",
    "            state_max = T[p.index(pmax)] \n",
    "        \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  38.04473161697388\n",
      "Modified Viterbi_1 Accuracy:  95.57522123893806\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_2(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Modified Viterbi_1 Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thus, we see that we have got a much better accuracy by using weighted transition probabilties.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('command', 'VERB'), ('command', 'NOUN')),\n",
       " (('Sandinista', 'VERB'), ('Sandinista', 'NOUN')),\n",
       " (('Eveready', 'VERB'), ('Eveready', 'NOUN')),\n",
       " (('*T*-252', 'VERB'), ('*T*-252', 'X')),\n",
       " (('up', 'ADV'), ('up', 'PRT'))]"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the incorrectly tagged words\n",
    "[j for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0] != j[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following list of words have been **correctly POS tagged by Viterbi_1** as compared to vanilla Viterbi Algorithm:\n",
    "\n",
    "* Contra:correctly tagged as NOUN\n",
    "* Honduras:correctly tagged as NOUN\n",
    "* complaining: correctly tagged as VERB\n",
    "* Bucking: correctly tagged as VERB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viterbi Modification-Technique II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**second solution for unknown words:** \n",
    "\n",
    "* backoff to rule based tagger in case of unknown words.\n",
    "* we further observe that POS tag 'X' can be easily encapsulated in regex rule, so we extract it only based on ruled based tagged.\n",
    "\n",
    "Let's define a rule based tagger as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify patterns for tagging\n",
    "patterns = [\n",
    "    (r'.*ing$', 'VERB'),              # gerund\n",
    "    (r'.*ed$', 'VERB'),               # past tense \n",
    "    (r'.*es$', 'VERB'),               # verb    \n",
    "    (r'.*\\'s$', 'NOUN'),              # possessive nouns\n",
    "    (r'.*s$', 'NOUN'),                # plural nouns\n",
    "    (r'\\*T?\\*?-[0-9]+$', 'X'),        # X\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), # cardinal numbers\n",
    "    (r'.*', 'NOUN')                   # nouns\n",
    "]\n",
    "\n",
    "# rule based tagger\n",
    "rule_based_tagger = nltk.RegexpTagger(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modification in Viterbi Algorithm : Backoff to rule based tagger in case unknown word is encountered.\n",
    "def Viterbi_2(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        state_max = rule_based_tagger.tag([word])[0][1]       \n",
    "       \n",
    "        \n",
    "        if(pmax==0):\n",
    "            state_max = rule_based_tagger.tag([word])[0][1] # assign based on rule based tagger\n",
    "        else:\n",
    "            if state_max != 'X':\n",
    "                # getting state for which probability is maximum\n",
    "                state_max = T[p.index(pmax)]                \n",
    "            \n",
    "        \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  34.20582127571106\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_2(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Viterbi_2 Accuracy:  97.34513274336283\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Modified Viterbi_2 Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('command', 'VERB'), ('command', 'NOUN')),\n",
       " (('drew', 'NOUN'), ('drew', 'VERB')),\n",
       " (('up', 'ADV'), ('up', 'PRT'))]"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the incorrectly tagged words\n",
    "[j for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0] != j[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following list of words have been correctly POS tagged by Viterbi_2 as compared to vanilla Viterbi Algorithm:\n",
    "\n",
    "* Contra:correctly tagged as NOUN\n",
    "* Honduras:correctly tagged as NOUN\n",
    "* complaining: correctly tagged as VERB\n",
    "* Bucking: correctly tagged as VERB\n",
    "\n",
    "the following list of words has been correctly tagged by Viterbi_2 as compared to Viterbi_1\n",
    "\n",
    "* Sandinista: correctly tagged as NOUN\n",
    "* Eveready: correctly tagged as NOUN\n",
    "* `*T*-252`: correctly tagged as 'X'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**further modification in Viterb_2:** We know that the rule based tagger assigns 'NOUN' by default if word does not fall in any rule, to correct this let's assign the tags for any such word based purely on transition probability of tags.\n",
    "\n",
    "So, first we will modify the rule based tagger to output 'NN' instead of 'NOUN' in case word does not satisfy any rules. We also observe that any capitalized word can still be defaulted as 'NOUN' so will add one more rule for that case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify patterns for tagging\n",
    "patterns = [\n",
    "    (r'.*ing$', 'VERB'),              # gerund\n",
    "    (r'.*ed$', 'VERB'),               # past tense \n",
    "    (r'.*es$', 'VERB'),               # verb    \n",
    "    (r'.*\\'s$', 'NOUN'),              # possessive nouns\n",
    "    (r'.*s$', 'NOUN'),                # plural nouns\n",
    "    (r'\\*T?\\*?-[0-9]+$', 'X'),        # X\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), # cardinal numbers\n",
    "    (r'^[A-Z][a-z].*', 'NOUN'),       # NOUN\n",
    "    (r'.*', 'NN')                     # default\n",
    "]\n",
    "\n",
    "# rule based tagger\n",
    "rule_based_tagger = nltk.RegexpTagger(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified Viterbi\n",
    "def Viterbi_2(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        p_transition =[] # for storing transition probabilities\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "            # find POS tag occurance probability\n",
    "            tag_p = [pair[1] for pair in tag_prob if pair[0]==tag ]\n",
    "            \n",
    "            # calculate the transition prob weighted by tag occurance probability.\n",
    "            transition_p = tag_p[0]*transition_p\n",
    "            p_transition.append(transition_p)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        state_max = rule_based_tagger.tag([word])[0][1] \n",
    "        \n",
    "      \n",
    "        # getting state for which probability is maximum\n",
    "        if(pmax==0):\n",
    "            state_max = rule_based_tagger.tag([word])[0][1] # assign based on rule based tagger\n",
    "            \n",
    "            # if unknown word does not satisfy any rule, find the tag with maximum transition probability\n",
    "            if state_max == 'NN':\n",
    "                pmax = max(p_transition)\n",
    "                state_max = T[p_transition.index(pmax)]                 \n",
    "                \n",
    "        else:\n",
    "             if state_max != 'X':\n",
    "                # getting state for which probability is maximum\n",
    "                state_max = T[p.index(pmax)] \n",
    "        \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  38.43364071846008\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_2(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Viterbi Algorithm Accuracy:  98.23008849557522\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Modified Viterbi Algorithm Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that much better accuracy is obtained now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('command', 'VERB'), ('command', 'NOUN')), (('up', 'ADV'), ('up', 'PRT'))]"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the incorrectly tagged words\n",
    "[j for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0] != j[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following list of words have been correctly POS tagged by Viterbi_2 as compared to vanilla Viterbi Algorithm:\n",
    "* Contra:correctly tagged as NOUN\n",
    "* Honduras:correctly tagged as NOUN\n",
    "* complaining: correctly tagged as VERB\n",
    "* Bucking: correctly tagged as VERB\n",
    "\n",
    "the following list of words has been correctly tagged by Viterbi_2 as compared to Viterbi_1\n",
    "* Sandinista: correctly tagged as NOUN\n",
    "* Eveready: correctly tagged as NOUN\n",
    "* `*T*-252`: correctly tagged as 'X'\n",
    "* drew: correctly tagged as VERB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate vanilla Viterbi and modified Viterbi on entire test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tagged_words = [tup[0] for sent in test_set for tup in sent]\n",
    "test_run_base = [tup for sent in test_set for tup in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  1647.6785893440247\n",
      "Modified Viterbi Algorithm Accuracy:  91.51881458373951\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Modified Viterbi Algorithm Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  2186.4629657268524\n",
      "Modified Viterbi Algorithm Accuracy:  95.43770715539091\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_2(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Modified Viterbi Algorithm Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating tagging on sample 'Test_sentences.txt' file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Test_sentences.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test_sent = text.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test_sent = test_sentences[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Android is a mobile operating system developed by Google.',\n",
       " 'Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 2013.',\n",
       " \"Google and Twitter made a deal in 2015 that gave Google access to Twitter's firehose.\",\n",
       " 'Twitter is an online news and social networking service on which users post and interact with messages known as tweets.',\n",
       " 'Before entering politics, Donald Trump was a domineering businessman and a television personality.',\n",
       " 'The 2018 FIFA World Cup is the 21st FIFA World Cup, an international football tournament contested once every four years.',\n",
       " 'This is the first World Cup to be held in Eastern Europe and the 11th time that it has been held in Europe.',\n",
       " 'Show me the cheapest round trips from Dallas to Atlanta']"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of untagged words\n",
    "sample_test_words = [word for sent in sample_test_sent for word in sent.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  41.50299906730652\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "sample_tagged_seq = Viterbi(sample_test_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Android', 'NUM'),\n",
       " ('is', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('mobile', 'ADJ'),\n",
       " ('operating', 'NOUN'),\n",
       " ('system', 'NOUN'),\n",
       " ('developed', 'VERB'),\n",
       " ('by', 'ADP'),\n",
       " ('Google.', 'NUM'),\n",
       " ('Android', 'NUM'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('best-selling', 'ADJ'),\n",
       " ('OS', 'NUM'),\n",
       " ('worldwide', 'NUM'),\n",
       " ('on', 'ADP'),\n",
       " ('smartphones', 'NUM'),\n",
       " ('since', 'ADP'),\n",
       " ('2011', 'NUM'),\n",
       " ('and', 'CONJ'),\n",
       " ('on', 'ADP'),\n",
       " ('tablets', 'NOUN'),\n",
       " ('since', 'ADP'),\n",
       " ('2013.', 'NUM'),\n",
       " ('Google', 'NUM'),\n",
       " ('and', 'CONJ'),\n",
       " ('Twitter', 'NUM'),\n",
       " ('made', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('deal', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('2015', 'NUM'),\n",
       " ('that', 'ADP'),\n",
       " ('gave', 'VERB'),\n",
       " ('Google', 'NUM'),\n",
       " ('access', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " (\"Twitter's\", 'NUM'),\n",
       " ('firehose.', 'NUM'),\n",
       " ('Twitter', 'NUM'),\n",
       " ('is', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('online', 'NUM'),\n",
       " ('news', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('social', 'ADJ'),\n",
       " ('networking', 'NOUN'),\n",
       " ('service', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('which', 'DET'),\n",
       " ('users', 'NOUN'),\n",
       " ('post', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('interact', 'NUM'),\n",
       " ('with', 'ADP'),\n",
       " ('messages', 'NUM'),\n",
       " ('known', 'VERB'),\n",
       " ('as', 'ADP'),\n",
       " ('tweets.', 'NUM'),\n",
       " ('Before', 'ADP'),\n",
       " ('entering', 'VERB'),\n",
       " ('politics,', 'NUM'),\n",
       " ('Donald', 'NOUN'),\n",
       " ('Trump', 'NOUN'),\n",
       " ('was', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('domineering', 'NUM'),\n",
       " ('businessman', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('a', 'DET'),\n",
       " ('television', 'NOUN'),\n",
       " ('personality.', 'NUM'),\n",
       " ('The', 'DET'),\n",
       " ('2018', 'NUM'),\n",
       " ('FIFA', 'NUM'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup', 'NUM'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('21st', 'NUM'),\n",
       " ('FIFA', 'NUM'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup,', 'NUM'),\n",
       " ('an', 'DET'),\n",
       " ('international', 'ADJ'),\n",
       " ('football', 'NOUN'),\n",
       " ('tournament', 'NUM'),\n",
       " ('contested', 'NUM'),\n",
       " ('once', 'ADV'),\n",
       " ('every', 'DET'),\n",
       " ('four', 'NUM'),\n",
       " ('years.', 'NUM'),\n",
       " ('This', 'DET'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('first', 'ADJ'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup', 'NUM'),\n",
       " ('to', 'PRT'),\n",
       " ('be', 'VERB'),\n",
       " ('held', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Eastern', 'NOUN'),\n",
       " ('Europe', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('the', 'DET'),\n",
       " ('11th', 'ADJ'),\n",
       " ('time', 'NOUN'),\n",
       " ('that', 'ADP'),\n",
       " ('it', 'PRON'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('held', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Europe.', 'NUM'),\n",
       " ('Show', 'NOUN'),\n",
       " ('me', 'PRON'),\n",
       " ('the', 'DET'),\n",
       " ('cheapest', 'ADJ'),\n",
       " ('round', 'NOUN'),\n",
       " ('trips', 'NUM'),\n",
       " ('from', 'ADP'),\n",
       " ('Dallas', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('Atlanta', 'NOUN')]"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tagged_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that several words have been misclassified by vanilla Viterbi POS tagger, for example:\n",
    "* Android as NUM\n",
    "* Google as NUM\n",
    "* OS as NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  40.423513650894165\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "sample_tagged_seq = Viterbi_2(sample_test_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Android', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('mobile', 'ADJ'),\n",
       " ('operating', 'NOUN'),\n",
       " ('system', 'NOUN'),\n",
       " ('developed', 'VERB'),\n",
       " ('by', 'ADP'),\n",
       " ('Google.', 'NOUN'),\n",
       " ('Android', 'NOUN'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('best-selling', 'ADJ'),\n",
       " ('OS', 'NOUN'),\n",
       " ('worldwide', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('smartphones', 'VERB'),\n",
       " ('since', 'ADP'),\n",
       " ('2011', 'NUM'),\n",
       " ('and', 'CONJ'),\n",
       " ('on', 'ADP'),\n",
       " ('tablets', 'NOUN'),\n",
       " ('since', 'ADP'),\n",
       " ('2013.', 'NOUN'),\n",
       " ('Google', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('Twitter', 'NOUN'),\n",
       " ('made', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('deal', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('2015', 'NUM'),\n",
       " ('that', 'ADP'),\n",
       " ('gave', 'VERB'),\n",
       " ('Google', 'NOUN'),\n",
       " ('access', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " (\"Twitter's\", 'NOUN'),\n",
       " ('firehose.', 'NOUN'),\n",
       " ('Twitter', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('online', 'NOUN'),\n",
       " ('news', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('social', 'ADJ'),\n",
       " ('networking', 'NOUN'),\n",
       " ('service', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('which', 'DET'),\n",
       " ('users', 'NOUN'),\n",
       " ('post', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('interact', 'NOUN'),\n",
       " ('with', 'ADP'),\n",
       " ('messages', 'VERB'),\n",
       " ('known', 'VERB'),\n",
       " ('as', 'ADP'),\n",
       " ('tweets.', 'NOUN'),\n",
       " ('Before', 'ADP'),\n",
       " ('entering', 'VERB'),\n",
       " ('politics,', 'NOUN'),\n",
       " ('Donald', 'NOUN'),\n",
       " ('Trump', 'NOUN'),\n",
       " ('was', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('domineering', 'VERB'),\n",
       " ('businessman', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('a', 'DET'),\n",
       " ('television', 'NOUN'),\n",
       " ('personality.', 'NOUN'),\n",
       " ('The', 'DET'),\n",
       " ('2018', 'NUM'),\n",
       " ('FIFA', 'NOUN'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('21st', 'NOUN'),\n",
       " ('FIFA', 'NOUN'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup,', 'NOUN'),\n",
       " ('an', 'DET'),\n",
       " ('international', 'ADJ'),\n",
       " ('football', 'NOUN'),\n",
       " ('tournament', 'NOUN'),\n",
       " ('contested', 'VERB'),\n",
       " ('once', 'ADV'),\n",
       " ('every', 'DET'),\n",
       " ('four', 'NUM'),\n",
       " ('years.', 'NOUN'),\n",
       " ('This', 'DET'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('first', 'ADJ'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('be', 'VERB'),\n",
       " ('held', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Eastern', 'NOUN'),\n",
       " ('Europe', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('the', 'DET'),\n",
       " ('11th', 'ADJ'),\n",
       " ('time', 'NOUN'),\n",
       " ('that', 'ADP'),\n",
       " ('it', 'PRON'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('held', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Europe.', 'NOUN'),\n",
       " ('Show', 'NOUN'),\n",
       " ('me', 'PRON'),\n",
       " ('the', 'DET'),\n",
       " ('cheapest', 'ADJ'),\n",
       " ('round', 'NOUN'),\n",
       " ('trips', 'NOUN'),\n",
       " ('from', 'ADP'),\n",
       " ('Dallas', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('Atlanta', 'NOUN')]"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tagged_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these cases were correctly POS tagged by Viterbi_2:\n",
    "* Android as NOUN\n",
    "* Google as NOUN\n",
    "* OS as NOUN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the tagging accuracies of the modifications with the vanilla Viterbi algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of vanilla Viterbi Algorithm: **91.52%**\n",
    "\n",
    "The accuracy of modified Viterbi Algorithm: **95.44%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List down cases which were incorrectly tagged by original POS tagger and got corrected by your modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cases were incorrectly tagged which got corrected by modified Viterbi Algorithm:\n",
    "\n",
    "* Contra:correctly tagged as NOUN\n",
    "* Honduras:correctly tagged as NOUN\n",
    "* complaining: correctly tagged as VERB\n",
    "* Bucking: correctly tagged as VERB\n",
    "* Sandinista: correctly tagged as NOUN\n",
    "* Eveready: correctly tagged as NOUN\n",
    "* `*T*-252`: correctly tagged as 'X'\n",
    "* drew: correctly tagged as VERB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
